
---
title: "D√©tection de faux billets avec R"
author: "Abdelmajid EL HOU - data analyst (*[Mon ePortfolio](https://abdelmajidlh.github.io/ePortfolio/)*) "
date: "02/02/2022"
output: 
  html_document:
    toc: true # table of content true
    toc_depth: 3  # upto three depths of headings (specified by #, ## and ###)
    number_sections: true  ## if you want number sections at each table header
    theme: united  # many options for theme, this one is my favorite.
    highlight: tango  # specifies the syntax highlighting style
    #css: my.css   # you can add your custom css, should be in same folder
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, out.width="80%", fig.cap=""}
#knitr::include_graphics("data/logo.png")
```

# Introduction
## Contexte du projet 
L‚ÄôOrganisation nationale de lutte contre le faux-monnayage, ou ONCFM, est une organisation publique ayant pour objectif de mettre en place des m√©thodes d‚Äôidentification des contrefa√ßons des billets en euros. Dans le cadre de cette lutte, l'ONCFM souhaite mettre en place un algorithme qui soit capable de diff√©rencier automatiquement les vrais des faux billets.

## Objectif
Lorsqu‚Äôun billet arrive, une machine consigne l‚Äôensemble de ses caract√©ristiques g√©om√©triques. Au travers des ann√©es de lutte, l'ONCFM a observ√© des diff√©rences de dimensions entre les vrais et les faux billets. Ces diff√©rences sont difficilement notables √† l‚Äô≈ìil nu, mais une machine devrait sans probl√®me arriver √† les diff√©rencier. 
Ainsi, il faudrait construire un **algorithme** qui, √† partir des caract√©ristiques g√©om√©triques d‚Äôun billet, serait capable de d√©finir si ce dernier est un vrai ou un faux billet.

## Com√©tences √† mobiliser
Les comp√©tences √† acqu√©rir dans ce projet:

- R√©aliser une analyse pr√©dictive
- Op√©rer des classifications automatiques pour partitionner les donn√©es
- R√©aliser une r√©gression logistique
- R√©aliser une r√©gression lin√©aire

# Importation et nettoyage des donn√©es
```{r}
# D√©finir le dossier de travail
setwd("C:/Users/abdel/Desktop/Projet 10/P10_Abdelmajid_EL_HOU")
```

## Packages et fonctions
```{r}
suppressMessages(require(tidyverse)) # pour la manipulation et la visualisation des donn√©es
suppressMessages(require(DataExplorer))
suppressMessages(require(e1071))
suppressMessages(require(caret)) # regression logistique
suppressMessages(require(caTools))
#suppressMessages(require(InformationValue))
suppressMessages(require(missMDA)) # offre des fonctions R facilitant l'imputation des donn√©es manquantes
suppressMessages(require(ggplot2))
suppressMessages(require(corrplot))
suppressMessages(require(purrr))
suppressMessages(require(hrbrthemes))
suppressMessages(require(visdat))
suppressMessages(require(knitr))

# tester la normalit√© & variances
suppressMessages(require(ggpubr)) # pour cr√©er facilement des graphiques pr√™ts √† la publication
suppressMessages(require(rstatix)) # offre des fonctions R facilitant les analyses statistiques
#suppressMessages(require(car)) # tests statistiques

#clustering
suppressMessages(require(FactoMineR))
suppressMessages(require(FactoInvestigate))
suppressMessages(require(factoextra))
suppressMessages(require(cluster))
suppressMessages(require(gridExtra))
suppressMessages(require(DataExplorer))
```
## Pr√©paration des donn√©es
```{r}
# importer le fichier csv
df =  read.csv2("data/billets.csv", sep = ";") # encoding = "UTF-8"
```

```{r}
# Convertir les cha√Ænes de caract√®res en numeric dans notre jeu de donn√©es
i = c(2,3,4,5,6,7)

df[ , i] <- apply(df[ , i], 2,
                    function(x) as.numeric(as.character(x)))

```

```{r}
# Afficher les premi√®res lignes
kable(df[1:5,], caption = "Head dataframe")
```

```{r}
# Taille de mon jeu de donn√©es
dim(df)

# nombre de faux/vrai billets
table(df$is_genuine)
```

- Le jeu de donn√©es est compos√© de 1500 observations (1000 vrais billets et 500 faux) et de 7 variables (1 cat√©gorielle et 6 num√©riques).

```{r}
# Ajouter une colonne ID
df <- tibble::rowid_to_column(df, "ID")
```

## G√©rer les valeurs manquantes
 
### Visualisation des valeurs manquantes

```{r}
vis_miss(df) + theme(axis.text.x =  element_text(angle = 90))
```

- Nous avons au total 37 valeurs manquantes (0.3 % du total).
- Ces valeurs manquantes sont situ√©es au niveau de la colonne margin_low (2.47 %).

```{r}
# Cr√©er un nouveau jeu de donn√©es sans valeurs manquantes
df2 = df %>% filter(!is.na(margin_low))
```

### Imputation des valeurs manquantes par regression lin√©aire

La r√©gression lin√©aire multiple est une extension de la r√©gression lin√©aire simple utilis√©e pour pr√©dire une variable de r√©sultat (y) sur la base de multiples variables pr√©dictives distinctes (x).

Par exemple, avec trois variables pr√©dictives (*x*), la pr√©diction de *y* est exprim√©e par l'√©quation suivante :

$$y = b0 + b1*x1 + b2*x2 + b3*x3$$
* Les valeurs *b* sont appel√©es les poids de r√©gression (ou coefficients b√™ta).
* Elles mesurent l'association entre la variable pr√©dictive et le r√©sultat.
* *b_j* peut √™tre interpr√©t√© comme l'effet moyen sur *y* d'une augmentation d'une unit√© de *x_j*, en maintenant tous les autres pr√©dicteurs fixes.

#### Construire le mod√®le
Nous voulons construire un mod√®le d'estimation de la variable *margin_low* bas√© sur les autres variables num√©riques, comme suit :
$$margin\_low = b0 + b1*diagonal + b2*height\_left + b3*height\_right + b4*margin\_up + b5*length$$

```{r}
# Calculer les coefficients du mod√®le
model <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = df2)
summary(model)
```

#### Interpr√©tation
* La valeur *p* de la statistique F est < 2.2e-16, ce qui est hautement significatif. Cela signifie qu'au moins une des variables pr√©dictives est li√©e de mani√®re significative √† la variable de r√©sultat.

* Pour voir quelles variables pr√©dictives sont significatives, on peux examiner le tableau des coefficients, qui montre l'estimation des coefficients b√™ta de la r√©gression et les valeurs t-statistiques *p* associ√©es :


```{r}
summary(model)$coefficient
```

Pour un pr√©dicteur donn√©, la statistique $t$ √©value s'il existe ou non une *association significative* entre le *pr√©dicteur* et la variable de *r√©sultat*, c'est-√†-dire si le coefficient *b√™ta* du pr√©dicteur est significativement diff√©rent de z√©ro.

- On constate que les 5 variables g√©ometriques sont significativement associ√©es √† la variation de la variable $margin\_low$.

- Pour une variable pr√©dictive donn√©e, le coefficient (*b*) peut √™tre interpr√©t√© comme l'effet moyen sur $y$ d'une augmentation d'une unit√© de la variable pr√©dictive, toutes les autres variables pr√©dictives √©tant fixes.

- Enfin, l'√©quation de notre mod√®le peut √™tre √©crite comme suit :
$$margin\_low = 22.99 - 0.11*diagonal + 0.18*height\_left + 0.26*height\_right + 0.26*margin\_up - 0.41*length$$

L'intervalle de confiance du coefficient du mod√®le :

```{r}
confint(model)
```
#### √âvaluation de la pr√©cision du mod√®le
La qualit√© globale du mod√®le peut √™tre √©valu√©e en examinant le R-carr√© ($R^2$) et l'erreur standard r√©siduelle (*RSE*).

##### R-carr√©
- Dans la r√©gression lin√©aire multiple, le $R^2$ repr√©sente le **coefficient de corr√©lation** entre les valeurs observ√©es de la variable de r√©sultat ($y$) et les valeurs ajust√©es (c'est-√†-dire pr√©dites) de $y$. Pour cette raison, la valeur de $R$ sera toujours positive et sera comprise entre 0 et 1.


- $R^2$ repr√©sente la proportion de la variance, dans la variable de r√©sultat $y$, qui peut √™tre pr√©dite en connaissant la valeur des variables $x$. Une valeur $R^2$ proche de 1 indique que le mod√®le explique une grande partie de la variance de la variable de r√©sultat.

Un probl√®me avec le $R^2$, est qu'il augmentera toujours lorsque plus de variables sont ajout√©es au mod√®le, m√™me si ces variables ne sont que faiblement associ√©es √† la r√©ponse (James et al. 2014). Une solution consiste √† ajuster le $R^2$ en tenant compte du nombre de variables pr√©dictives.

L'ajustement de la valeur du "R carr√© ajust√©" dans la sortie du r√©sum√© est une correction pour le nombre de variables *x* incluses dans le mod√®le de pr√©diction.

**_Dans notre exemple, avec les 5 variables pr√©dictives, le $R^2$ ajust√© = 0,475, ce qui signifie que 47.5% de la variance de margin_low peut √™tre pr√©dite par les 5 variables._**

##### Residual Standard Error (RSE), ou sigma:
L'estimation $RSE$ donne une mesure de l'erreur de pr√©diction. Plus le RSE est faible, plus le mod√®le est pr√©cis (sur les donn√©es en question).

Le taux d'erreur peut √™tre estim√© en divisant $RSE$ par la variable de r√©sultat moyenne :

```{r}
sigma(model)/mean(df2$margin_low)
```
- la valeur est proche de 0, donc *notre mod√®le semble √™tre pr√©cis √† 90 %*.

##### D√©tection de la multicollin√©arit√© entre variables
* Dans la r√©gression multiple, deux variables pr√©dictives ou plus peuvent √™tre corr√©l√©es entre elles.  Cette situation est appel√©e **colin√©arit√©**.

* Il existe une situation extr√™me, appel√©e **multicollin√©arit√©**, o√π la colin√©arit√© existe entre trois variables ou plus, m√™me si aucune paire de variables ne pr√©sente une corr√©lation particuli√®rement √©lev√©e. Cela signifie qu'il existe une **redondance entre les variables pr√©dictives**.

* En pr√©sence de multicollin√©arit√©, la solution du mod√®le de r√©gression devient instable.

* Pour un pr√©dicteur donn√© ($p$), la multicollin√©arit√© peut √™tre √©valu√©e en calculant un score appel√© **facteur d'inflation de la variance** (ou *VIF*), qui mesure **√† quel point la variance d'un coefficient de r√©gression est gonfl√©e en raison de la multicollin√©arit√© du mod√®le**.

Face √† la multicollin√©arit√©, **les variables concern√©es doivent √™tre supprim√©es**, car la pr√©sence de la multicollin√©arit√© implique que l'information que cette variable fournit sur la r√©ponse est **redondante** en pr√©sence des autres variables (James et al. 2014,P. Bruce et Bruce (2017)). [Source](http://www.sthda.com/english/articles/39-regression-model-diagnostics/160-multicollinearity-essentials-and-vif-in-r/)

```{r}
# Detecter la multicolin√©arit√©
car::vif(model)
```
- Les scores des 5 variables sont proche de 1, donc aucune multi-colin√©arit√© n'est pr√©sente entre les variables.

#### Remplacer les valeurs manquantes dans le fichier original en appliquant le mod√®le
```{r}
# Utiliser le mod√®le pour pr√©dire la valeur de margin_low
df3 <- df %>% 
  mutate(pred = predict(model, .)) %>%
  mutate(margin_low = ifelse(is.na(margin_low), pred, margin_low))

# Voir le r√©sultat
df3 = df3 %>% select(ID, is_genuine, diagonal, height_left, height_right, margin_low, margin_up, length) %>% as.data.frame()

vis_miss(df3[,-1]) + theme(axis.text.x =  element_text(angle = 90))
```

- Les valeurs manquantes sont bien imput√©es..

# Analyse exploratoire des donn√©es
## Description des donn√©es

```{r}
# Calcul de la moyenne par cat√©gorie de billet
for (col in 3:ncol(df3)) {
    print(paste0("------",colnames(df3)[col], "------"),collapse ="\t")
    moy = tapply(df3[,col], df3[,2], mean)
    print(moy)
}
```

*Un portrait-robot d'un vrai billet :* 

- Diagonale : 171.98 mm.
- Hauteur mesur√©e √† gauche : 103.94 mm
- Hauteur mesur√©e √† droite : 103.80 mm,
- Marge entre le bord inf√©rieur et le bord de l'image : 4.11 mm
- Marge entre le bord sup√©rieur et le bord de l'image :3.05 mm,
- Longueur : 113.20 mm, 

## Distribution des variables
### Test de Normalit√©
Les tests de corr√©lation, de r√©gression, les tests t et l‚Äôanalyse de variance, supposent que les donn√©es suivent une distribution normale. Ces tests sont appel√©s tests param√©triques, car leur validit√© d√©pend de la distribution des donn√©es.

V√©rifier la normalit√© des donn√©es dans R par inspection visuelle (graphique QQ plot et distributions de densit√©) et par des tests de statistiques (test de Shapiro-Wilk) [source](https://www.datanovia.com/en/fr/lessons/test-de-normalite-dans-r/)

#### Visuellement

```{r}
#plot_histogram(data =df3, ggtheme = theme_classic())
par(mfrow=c(2,3))
for (col in 3:ncol(df3)) {
    mean <- mean(df3[,col])
    med  <- median(df3[,col])
    hist(df3[,col], col="lightblue", main = "", freq=FALSE, xlab = colnames(df3)[col])
    abline(v = mean, col = 'black', lwd = 2)
    abline(v = med, col = 'red', lwd = 2)
    text(mean, 0.5, "mean", col="black", srt=90,pos=1)
    text(med, 0.6, "median", col="red", srt=90,pos=1)
}

```


```{r, fig.height=8}
# QQ plot
qq_diagonal     = ggqqplot(data =df3$diagonal)
qq_height_left  = ggqqplot(data =df3$height_left)
qq_height_right = ggqqplot(data =df3$height_right)
qq_margin_low   = ggqqplot(data =df3$margin_low)
qq_margin_up    = ggqqplot(data =df3$margin_up)
qq_length       = ggqqplot(data =df3$length)

ggarrange(qq_diagonal, qq_height_left, qq_height_right, qq_margin_low, qq_margin_up, qq_length + rremove("x.text"), 
          labels = c("diagonal", "height_left", "height_right", "margin_low", "margin_up","length"),
          ncol = 2, nrow = 3)
```

- La distribution des variables semble etre normale, sauf pour $margin\_low$ et $length$

#### Test de normalit√© de Shapiro-Wilk
Il existe plusieurs m√©thodes pour √©valuer la normalit√©, notamment le test de normalit√© de **Kolmogorov-Smirnov (K-S)** ($n > = 5000$ ) et le test de **Shapiro-Wilk**.

- L‚Äôhypoth√®se nulle de ces tests est que ‚Äúla distribution de l‚Äô√©chantillon est normale‚Äù. Si le test est significatif, la distribution est non-normale.
- La m√©thode de Shapiro-Wilk est largement recommand√©e pour les tests de normalit√© et fournit une meilleure puissance que K-S. Il est bas√© sur la corr√©lation entre les donn√©es et les scores normaux correspondants (Ghasemi and Zahediasl 2012).

```{r, warning=FALSE}
# Test de Shapiro 
df3 %>% shapiro_test(diagonal, height_left, height_right, margin_low, margin_up, length)
```

- La p-value > 0,05 indiquant que la distribution des donn√©es n‚Äôest pas significativement diff√©rente de la distribution normale. En d‚Äôautres termes, nous pouvons supposer la normalit√©.
- Le test de shapiro indique que la distribution des variables $length$, $margin\_low$ et $margin\_up$ n'est pas significativement normale.

```{r}
# afficher les box plots
plot_boxplot(df3[,-1], "is_genuine", geom_boxplot_args = list(notch=TRUE), ggtheme = theme_classic())
```

Les box plots par cat√©gorie de billet montrent que les m√©dianes des deux groupes sont significativement diff√©rentes:

- valeurs plus fortes de la variable $length$ pour les vrais billets
- valeurs plus bas pour $margin\_low$ et $margin\_up$
- valeurs l√©g√®rement plus bas pour $height\_left$ et $height\_right$
- valeur l√©g√®rement plus fort pour $diagonal$

### Test d‚ÄôHomog√©n√©it√© des Variances - h√©t√©rosc√©dasticit√©
Certains tests statistiques, comme le test T sur deux √©chantillons ind√©pendants et le test ANOVA, supposent que les variances sont √©gales entre les groupes.

Il existe diff√©rents tests de variance qui peuvent √™tre utilis√©s pour √©valuer l‚Äô**√©galit√© des variances**. Il s‚Äôagit notamment:

    - Test F : Comparez les variances de deux groupes. Les donn√©es doivent √™tre normalement distribu√©es.
    - Test de Bartlett : Comparer les variances de deux groupes ou plus. Les donn√©es doivent √™tre normalement distribu√©es.
    - Le test de Levene : Une alternative robuste au test de Bartlett qui est moins sensible aux √©carts de normalit√©.
    - Test de Fligner-Killeen : un test non param√©trique qui est tr√®s robuste contre les √©carts de normalit√©.

‚ö†Ô∏è <span style="color:blue">*Il est √† noter que le test de Levene est le plus couramment utilis√© dans la litt√©rature.* </span>. [Source](https://www.datanovia.com/en/fr/lessons/test-dhomogeneite-des-variances-dans-r/)

Hypoth√®ses statistiques :

 * H0 : toutes les variances des echantillons sont √©gales
 * H1 : au moins deux d'entre elles diff√®rent.
 
Par cons√©quent, des valeurs $p$ inf√©rieures √† 0,05 sugg√®rent que les variances sont significativement diff√©rentes et que l'hypoth√®se d'homog√©n√©it√© de la variance a √©t√© viol√©e.

```{r}
# # Test de Levene avec de multiples variables ind√©pendantes. La fonction leveneTest() [package car] peut √™tre utilis√©e.
for (col in 3:ncol(df3)) {
  res = car::leveneTest(df3[,col] ~ as.factor(is_genuine), df3)
  print(colnames(df[col]))
  print(res)
  print("------------------------------------------------")
}
```

- L'hypoth√®se d'homog√©n√©it√© de la variance a √©t√© viol√©e pour les variables $height\_left$, $margin\_low$, et $length$.


### Identifier les corr√©lations entre les variables du dataframe
[Source : ](https://jkzorz.github.io/2019/06/11/Correlation-heatmaps.html)

```{r, fig.height=5, fig.width=5}
# Cr√©√©er une matrice de crr√©lation
cc = cor(select_if(df3[,-1], is.numeric), method = "spearman")

# Heatmap
#corrplot(cc, tl.col = "black", addrect = 4, tl.cex = 0.7)
plot_correlation(cc, ggtheme = theme_classic())
```

- La variable $length$ est corr√©l√©e fortement avec les variables $margines$ (corr√©lation n√©gative)
- $margin\_up$ et $margin\_low$ sont tr√®s corr√©l√©es positivement.

# Mod√®le : Classification automatique avec kmeans
L‚Äôobjectif est d‚Äôidentifier des groupes homog√®nes, partageant des caract√©ristiques similaires (s√©parer les vrai et les faux billets en se basant sur les donn√©es g√©om√©triques).



```{r, fig.height=8, fig.width=8}
#df3 = df3[,-8]
# Centrage r√©duction des donn√©es : pour √©viter que les variables √† forte variance p√®sent ind√ªment sur les r√©sultats
data.cr = scale(df3[,c(-1,-2)], center=T, scale=T)
data.cr = data.cr %>% as.data.frame()
#rownames(data.cr) = seq(1:nrow(df3))
#data.cr = tibble::rowid_to_column(as.data.frame(data.cr), "ID")
data.cr$is_genuine = df3$is_genuine
data.cr$ID = df3$ID
```

## Nombre ad√©quat de groupes

```{r, fig.height=5, fig.width=6}
# Identifier le nombre de centres optimals
grid.arrange(
fviz_nbclust(data.cr[c(-7,-8)], FUNcluster = kmeans, method = "wss"),
fviz_nbclust(data.cr[c(-7,-8)], FUNcluster = kmeans, method = "silhouette")
    ,nrow=1 )
```

* Le "coude" sugg√®re que 2 groupes pr√©servent l'information semblerait le nombre optimal


```{r}
# Kmeans avec les donn√©es centr√©es et r√©duites
#   center = 2 nombre de groupes demand√©s
#   nstart = 50 nombre d'essais avec diff√©rents individus de d√©part parce que les r√©sultats sont d√©pendants de l‚Äôinitialisation
# Set seed
set.seed(1234)
groupes.kmeans = kmeans(data.cr[c(-7,-8)], centers=2, nstart=50)
```

```{r, fig.height=7, fig.width=7, warning=FALSE}
# visualisation des clusters obtenus (projection sur le 1er plan factoriel) des deux m√©thodes
fviz_cluster(groupes.kmeans, data = data.cr[c(-7,-8)], main = "Kmeans 2", repel = TRUE, geom = c("point"), elipse.type = "euclid", ggtheme = theme_classic())
```
```{r}
#affichage des r√©sultats - centroides 
print(groupes.kmeans$centers)
```

* K-means clustering avec 2 clusters de taille 1004 et 496


```{r, warning=FALSE}
kmeans_basic_table <- data.frame(groupes.kmeans$size, groupes.kmeans$centers)
kmeans_basic_df <- data.frame(Cluster = groupes.kmeans$cluster, df3)
```


```{r}
# ggplot nombre de billets par cluster
ggplot(data = kmeans_basic_df, aes(y = Cluster)) +
  geom_bar(aes(fill = is_genuine)) +
  ggtitle("Nombre de faux/vrai billets par Cluster") +
  theme(plot.title = element_text(hjust = 0.5))
```

* Le premier cluster repr√©sente les vrai billets et le deuxi√®me, les faux billets

```{r}
# Matrice de confusion
table(df3$is_genuine, kmeans_basic_df$Cluster)
```
- Le mod√®le kmeans avec 2 centres repr√©sente efficacement les deux types de billets dans notre jeu de donn√©es
- La pr√©cision (accuracy) du mod√®le : (990+486)/1500 = **98.4 %**



# Mod√®le : R√©gression Logistique
* La r√©gression logistique est utilis√©e pour pr√©dire la classe (ou cat√©gorie) d'individus en fonction d'une ou plusieurs variables pr√©dictives (x). Elle est utilis√©e pour mod√©liser un r√©sultat binaire, c'est-√†-dire une variable qui ne peut avoir que deux valeurs possibles (ex. 0/1, oui/non, malade/non malade , **vrai**/**faux**).

* La r√©gression logistique appartient √† une famille, appel√©e mod√®le lin√©aire g√©n√©ralis√© (GLM), d√©velopp√©e pour √©tendre le mod√®le de r√©gression lin√©aire √† d'autres situations. D'autres synonymes sont la **r√©gression logistique binaire**, la **r√©gression logistique binomiale** et le **mod√®le logit** ([Source](http://www.sthda.com/english/articles/36-classification-methods-essentials/151-logistic-regression-essentials-in-r/)).

* La r√©gression logistique ne renvoie pas directement la classe des observations. Elle nous permet d'estimer la **probabilit√© (p)** d'appartenance √† une classe. La probabilit√© sera comprise entre **0** et **1**. Il faudra donc, d√©cider de la probabilit√© seuil √† partir de laquelle la cat√©gorie bascule de l'une √† l'autre. Par d√©faut, cette valeur est fix√©e √† $p = 0,5$, mais en r√©alit√©, elle doit √™tre fix√©e en fonction de l'objectif de l'analyse.

Dans cette partie, on va :

    - D√©finir l'√©quation de r√©gression logistique et les termes cl√©s tels que log-odds et logit.
    - effectuer une r√©gression logistique dans R et interpr√©ter les r√©sultats
    - faire des pr√©dictions sur de nouvelles donn√©es de test et √©valuer la pr√©cision du mod√®le.
    
## Pr√©paration des donn√©es
La r√©gression logistique fonctionne pour des donn√©es qui contiennent des variables pr√©dicteurs continues et/ou cat√©goriques.

L'ex√©cution des √©tapes suivantes peut am√©liorer la pr√©cision de notre mod√®le :

    - Supprimez les valeurs aberrantes potentielles
    - Utiliser les variables pr√©dicteurs normalement distribu√©es (ou faire la transformation logarithmique, racine ou box-cox, si ce n'est pas le cas).
    - Supprimez les variables pr√©dicteurs fortement corr√©l√©es pour minimiser l'overfitting (La pr√©sence de pr√©dicteurs fortement corr√©l√©s peut conduire √† une solution instable du mod√®le).
    
```{r}
# Inspecter les donn√©es
kable(df3[1:5,], caption = "Mon jeu de donn√©es")
```

## Calcul de la r√©gression logistique
Commen√ßant par utilier l'ensemble des variables.

* Pour des donn√©es binaires ou binomiales, la fonction lien est nomm√©e le logit (ce que l‚Äôon indique √† glm avec l‚Äôargument family=binomial(logit) : 
$$g(p) = log(p/1-p)$$. 
* La fonction logit est le logarithme de la probabilit√© $(p1‚àíp)$ ([source: qcbs, p54](http://r.qcbs.ca/workshop06/pres-fr/workshop06-pres-fr.html#54))

```{r}
# Modele logit
reg <- glm(as.factor(is_genuine) ~ diagonal + height_left + height_right + margin_low + margin_up + length, 
           data = df3, family = binomial(link = "logit"))
# model <- glm( is_genuine ~., data = train.data, family = binomial) # toutes les vars inclues
summary(reg)

```

- les  pr√©dicteurs significatifs sont : $height\_right$, $margin\_low$, $margin\_up$ et $length$

Notant que les fonctions coef() et summary() peuvent √™tre utilis√©es pour extraire uniquement les coefficients, comme suit :

```{r}
summary(reg)$coef
```


- Dans le cadre d‚Äôun mod√®le logistique, g√©n√©ralement on ne pr√©sente pas les coefficients du mod√®le mais **leur valeur exponentielle**, cette derni√®re correspondant en effet √† des **odds ratio**, √©galement appel√©s **rapports des cotes**. 
- L‚Äôodds ratio diff√®re du risque relatif. Cependent son interpr√©tation est similaire. 
- Un odds ratio de **1** signifie l‚Äô**absence d‚Äôeffet**. Un odds ratio largement **sup√©rieur √† 1** correspond √† une **augmentation du ph√©nom√®ne √©tudi√©** et un odds ratio largement **inf√©ieur √† 1** correspond √† une **diminution du ph√©nom√®ne √©tudi√©**([source](https://larmarange.github.io/analyse-R/regression-logistique.html#pr%C3%A9paration-des-donn%C3%A9es)).


## Interpretation
On constate que seuls 4 des 6 pr√©dicteurs sont associ√©s de mani√®re significative au r√©sultat.

Le coefficient estim√© de la variable length est $b = 5.91$ (positif). Cela signifie qu'une augmentation du $length$ est associ√©e √† une augmentation de la probabilit√© d'√™tre faut billet. Cependant, le coefficient de la variable $margin\_low$ est $b = -5.77$ (n√©gatif). Cela signifie qu'une augmentation de la $margin\_low$ est associ√©e √† une diminution de la probabilit√© d'√™tre faux billet.


D'apr√®s les r√©sultats de la r√©gression logistique, on peut remarquer que certaines variables ne sont pas statistiquement significatives. Leur maintien dans le mod√®le peut contribuer √† un ajustement excessif (**overfiting**). Elles doivent donc √™tre √©limin√©es. Ceci peut √™tre fait automatiquement en utilisant des techniques statistiques, y compris les m√©thodes de r√©gression pas √† pas (**stepwise regression**) et de r√©gression p√©nalis√©e (**penalized regression**). En bref, elles consistent √† s√©lectionner un mod√®le optimal avec un ensemble r√©duit de variables, sans compromettre la pr√©cision du mod√®le.

## Repr√©sentation graphique du mod√®le
Il est possible de repr√©senter graphiquement les diff√©rents odds ratios avec la fonction ggcoef_model de GGally.

```{r, message=FALSE, warning=FALSE}
library(GGally)
ggcoef_model(reg, exponentiate = TRUE)
```

## Repr√©sentation graphique des effets
L‚Äôextension effects propose une repr√©sentation graphique r√©sumant les effets de chaque variable du mod√®le.

```{r, fig.height=6, fig.width=8, message=FALSE, warning=FALSE}
library(effects)
plot(allEffects(reg))
```

## Matrice de confusion
Une mani√®re de tester la qualit√© d‚Äôun mod√®le est le calcul d‚Äôune matrice de confusion, c‚Äôest-√†-dire le tableau crois√© des valeurs observ√©es et celles des valeurs pr√©dites en appliquant le mod√®le aux donn√©es d‚Äôorigine.

La m√©thode predict avec l‚Äôargument type="response" permet d‚Äôappliquer notre mod√®le logistique √† un tableau de donn√©es et renvoie pour chaque individu la probabilit√© qu‚Äôil ait v√©cu le ph√©nom√®ne √©tudi√© (un vrai billet).

```{r}
billet.pred <- predict(reg, type = "response", newdata = df3)
head(billet.pred, n = 10)
```
Or notre variable √©tudi√©e est de type binaire. Nous devons donc transformer nos probabilit√©s pr√©dites en une variable du type ¬´ vrai / faux ¬ª. Usuellement, les probabilit√©s pr√©dites seront r√©unies en deux groupes selon qu‚Äôelles soient sup√©rieures ou inf√©rieures √† la moiti√©. La matrice de confusion est alors √©gale √† :

```{r}
table(billet.pred > 0.5, df3$is_genuine)
```

```{r}
accuracy<- (491+996)/ (491+4+9+996)
print(accuracy)
```
‚ö†Ô∏è * Nous avons donc 13 (4+9) pr√©dictions incorrectes sur un total de 1500, soit un taux de mauvais classement de 0.87 %.
‚ö†Ô∏è * La pr√©cision (accuracy) du mod√®le est de 99.13%


## Identifier les variables ayant un effet significatif
Les $p-values$ associ√©es aux odds ratios nous indique si un odd ratio est significativement diff√©rent de 1, par rapport √† la modalit√© de r√©f√©rence. Mais cela n‚Äôindique pas si globalement une variable a un effet significatif sur le mod√®le. Pour tester l‚Äôeffet global sur un mod√®le, on peut avoir recours √† la fonction drop1. Cette derni√®re va tour √† tour supprimer chaque variable du mod√®le et r√©aliser une analyse de variance (ANOVA) pour voir si la variance change significativement ou d'appliquer une ANOVA dir√©ctement.

```{r}
#drop1(reg, test = "Chisq")
Anova(reg)
```

La suppression des variables $diagonal$ et $height\_left$ ne modifient significativement pas le mod√®le, indiquant l‚Äôabsence d‚Äôeffet de ces variables.

## S√©lection de mod√®les
Il est toujours tentant lorsque l‚Äôon recherche les facteurs associ√©s √† un ph√©nom√®ne d‚Äôinclure un nombre important de variables explicatives potentielles dans un mod√®le logistique. Cependant, un tel mod√®le n‚Äôest pas forc√©ment le plus efficace et certaines variables n‚Äôauront probablement pas d‚Äôeffet significatif sur la variable d‚Äôint√©r√™t.

La technique de s√©lection descendante pas √† pas est une approche visant √† am√©liorer son mod√®le explicatif. On r√©alise un premier mod√®le avec toutes les variables sp√©cifi√©es, puis on regarde s‚Äôil est possible d‚Äôam√©liorer le mod√®le en supprimant une des variables du mod√®le. Si plusieurs variables permettent d‚Äôam√©liorer le mod√®le, on supprimera la variable dont la suppression am√©liorera le plus le mod√®le. Puis on recommence le m√™me proc√©d√© pour voir si la suppression d‚Äôune seconde variable peut encore am√©liorer le mod√®le et ainsi de suite. Lorsque le mod√®le ne peut plus √™tre am√©liorer par la suppresion d‚Äôune variable, on s‚Äôarr√™te.

Il faut √©galement d√©finir un crit√®re pour d√©terminer la qualit√© d‚Äôun mod√®le. L‚Äôun des plus utilis√©s est le *Akaike Information Criterion* ou *AIC*. **Plus l‚ÄôAIC sera faible, meilleure sera le mod√®le**.

La fonction **step** permet justement de s√©lectionner le **meilleur mod√®le par une proc√©dure pas √† pas descendante bas√©e sur la minimisation de l‚ÄôAIC**. La fonction affiche les diff√©rentes √©tapes de la s√©lection et renvoie le mod√®le final.

```{r}
reg2 <- step(reg)
```

* Le mod√®le initial a un AIC de 98.68. √Ä la premi√®re √©tape, il apparait que la suppression de la variable *diagonal* permet de diminuer l‚ÄôAIC √† 96.69. Lors de la seconde √©tape, toute suppression d‚Äôune autre variable ferait augmenter l‚ÄôAIC. La proc√©dure s‚Äôarr√™te donc.

Pour obtenir directement l‚ÄôAIC d‚Äôun mod√®le donn√©, on peut utiliser la fonction AIC.
```{r}
AIC(reg)
AIC(reg2)
```
Effectuer une analyse de variance ou ANOVA pour comparer les deux mod√®les :
```{r}
anova(reg, reg2, test = "Chisq")
```

- Il n‚Äôy a pas de diff√©rences significatives entre nos deux mod√®les (notre second mod√®le explique tout autant de variance que notre premier mod√®le, tout en √©tant plus parcimonieux).

## Mise √† jour du mod√®le
On supprime les variables non significatifs ($height\_left$ et $diagonal$) du mod√®le et on recalcul les coefficients.

```{r}
reg3 <- update(reg, ~. - height_left - diagonal)
summary(reg3)
```


```{r}
# Performance du mod√®le mis √† jour
billet.pred <- predict(reg3, type = "response", newdata = df3)
table(billet.pred > 0.5, df3$is_genuine)
```


```{r}
accuracy<- (492+997)/ (492+3+8+997)
print(accuracy)
```
üî¥ On observe une leg√®re am√©lioration du mod√®le (99.26% au lieu de 99.13%).


## Tester le mod√®le sur des donn√©es divis√©es (training/test)
Les performances des deux mod√®les (logit et step) sont √©gales sur le jeu de donn√©es complet. Testant le mod√®le sur un jeu de donn√©es training et test.

```{r}
# Split le dataframe en train/test
set.seed(5)
split = sample.split(df3$is_genuine)
train.data = subset(df3, split==TRUE)
test.data = subset(df3, split==FALSE)
```

### Performances des mod√®les
#### Mod√®le logit
```{r}
# Entrainer le mod√®le logit sur le jeu de donn√©es train
reg4_logit = glm(as.factor(is_genuine) ~ height_right + margin_low + margin_up + length, 
           data = train.data, family = binomial(link = "logit"))

# Performance du mod√®le sur le jeu test
reg4_pred_logit_test = predict(reg4_logit, type = "response", newdata = test.data)

#caret::confusionMatrix(table(reg4_pred_test > 0.5, test.data$is_genuine))
table(reg4_pred_logit_test > 0.5, test.data$is_genuine)
```

üî¥ * Nous avons seulement 5 pr√©dictions incorrectes sur un total de 500, soit un taux de mauvais classement de 1 %.

üî¥ * L'accuracy du mod√®le est de 99 %

#### Mod√®le step
```{r}
# Entrainer le mod√®le "step" sur le jeu de donn√©es train
reg4_step = step(reg4_logit)

# Performance du mod√®le "step" sur le jeu de donn√©es test
reg4_pred_step_test <- predict(reg4_step, type = "response", newdata = test.data)
table(reg4_pred_step_test >0.5, test.data$is_genuine)
```

üî¥ Les deux mod√®les ont la m√™me performance (accuracy de 99%)


#### Courbe ROC 
Receiver Operating Characteristic Curve (ROCR). On peut en g√©n√©rer gr√¢ce au package ROCR ([source](http://www.duclert.org/r-apprentissage/courbes-ROC-R.php)).

Sp√©cificit√© et sensibilit√© :

    - la sensibilit√© est : TP / (TP + FN) = TP / P.
    - la sp√©cificit√© est : TN / (TN + FP) = TN / N.

avec

    * TP (true positives) : les pr√©dits positifs qui le sont vraiment.
    * FP (false positives) : les pr√©dits positifs qui sont en fait n√©gatifs.
    * TN (true negatives) : les pr√©dits n√©gatifs qui le sont vraiment.
    * FN (false negatives) : les pr√©dits n√©gatifs qui sont en fait positifs.
    * P (positives) : tous les positifs quelque soit l'√©tat de leur pr√©diction. P = TP + FN.
    * N (negatives) : tous les n√©gatifs quelque soit l'√©tat de leur pr√©diction. N = TN + FP.

```{r}
# ROCR ored_logit
library(ROCR)
rocr_pred = prediction(reg4_pred_logit_test, test.data$is_genuine)
perf_ROCR = performance(rocr_pred, "auc")
perf_ROCR@y.values
```
```{r}
# Visualisation graphique
perf_ROCR = performance(rocr_pred, "tpr", "fpr")
plot(perf_ROCR, colorize=TRUE)
```

## Cross validation
Le package carret (Classification And REgression Training) int√®gre plusieurs fonctions pour faire du machine learnin (comme sklearn dans Python).

M√™me si ‚Äúcaret‚Äù propose des techniques de r√©√©chantillonnage pour l‚Äô√©valuation des mod√®les, nous allons subdiviser les donn√©es en √©chantillons d‚Äôapprentissage (70%) et de test (30%). Nous utilisons la commande createDataPartition() de la librairie ‚Äúcaret‚Äù ([source](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwja7rDAzcn1AhWQMBQKHTwLCi8QFnoECAMQAQ&url=http%3A%2F%2Feric.univ-lyon2.fr%2F~ricco%2Ftanagra%2Ffichiers%2Ffr_Tanagra_package_caret.pdf&usg=AOvVaw0OIWAgbsqD8iEDVrNVxza7)).


```{r}
# Recoder la variable r√©ponse en factor dans le df3
df3 <- df3 %>%
  mutate(is_genuine = factor(is_genuine))
```
### Echantillonage
Nous effectuons un √©chantillonnage stratifi√© sur la variable cible (is_genuine). Les proportions des classes devraient √™tre respect√©es dans les sous-√©chantillons.

```{r}
# Echantillonnage al√©atoire en √©quilibrant les proportions de billets
set.seed(100)
trainIndex <- createDataPartition(df3$is_genuine, p=0.7, list=F)
print(length(trainIndex))
```

```{r}
#data frame pour les individus en apprentissage 
train = df3[trainIndex,] 
print(dim(train))
```

Et pour l‚Äô√©chantillon test, nous passons par l‚Äôindi√ßage n√©gatif qui indique les individus √† exclure.
```{r}
#data frame pour les individus en test 
test <- df3[-trainIndex,] 
print(dim(test))
```
Nous v√©rifions la distribution des classes.
```{r}
#fr√©quences relatives des classes dans l'√©ch. d'apprentissage 
print(prop.table(table(train$is_genuine)))

#distribution des classes dans l'√©ch. test 
print(prop.table(table(test$is_genuine)))
```
### Mod√®le de regression retenu
```{r, warning=FALSE}
#param√®tre du processus d'apprentissage - cross validation
fitControl = trainControl(method = "cv", number = 10)

#apprentissage - r√©gression logistique 
m_lr <- train(is_genuine ~ height_right + margin_low + margin_up + length, 
              data = train, method="glm", trControl=fitControl, family = "binomial")

kable(m_lr$results, caption = "Description")
```

Le mod√®le sous-jacent est accessible via la propri√©t√© $finalModel

```{r}
print(m_lr$finalModel)
```
- l'AIC est beaucoup plus faible par rapport aux enciens mod√®les (~ 96)

### Pr√©diction sur l‚Äô√©chantillon test
Pour √©valuer la qualit√© de notre mod√®le, nous l‚Äôappliquons sur l‚Äô√©chantillon test

```{r}
#prediction 
pred = predict(m_lr, newdata=test) 

#distribution des classes pr√©dites 
print(table(pred))
```
üî¥ Il y a 302 pr√©dictions positives c.-√†-d. 302 billets de l‚Äô√©chantillon test sont d√©sign√©es vrai billets !

### Matrice de confusion et indicateurs d‚Äô√©valuation
La matrice de confusion mat√©rialise la confrontation entre les classes observ√©es et pr√©dites. Des indicateurs (m√©triques) interpr√©tables en sont d√©duits [source](http://topepo.github.io/caret/measuring-performance.html#measures-for-predicted-classes).

Nous utilisons la commande confusionMatrix(). Un troisi√®me param√®tre permet de d√©signer la modalit√© cible, n√©cessaire pour le calcul de certains indicateurs. Dans notre cas, nous cherchons avant tout √† identifier les vrai billets (is_genuine = True).

```{r}
#matrice de confusion 
mat = confusionMatrix(data=pred, reference=test$is_genuine, positive="True") 
print(mat)
```

- Le taux de succ√®s (accuracy, √† ne pas confondre avec la pr√©cision) est 99.56%. 
- L‚Äôintervalle de confiance √† 95% est fournie. En effet, l‚Äôensemble de test n‚Äôest qu‚Äôun √©chantillon repr√©sentatif (au mieux) de la population. Les taux mesur√©s sont assortis d‚Äôune certaine incertitude.
Nous disposons d‚Äôautres indicateurs, en particulier la **sensibilit√©** qui, associ√©e √† la classe positive ‚Äúis_genuine = True‚Äù, est √©gale √† 300/(300+0) = 100 %

### Autre m√©thode d'√©valuation du mod√®le
#### Courbe LIFT (courbe de gain)
La courbe LIFT ou courbe de gain est utilis√©e pour mesurer l‚Äôefficacit√© d‚Äôun ciblage ([scoring](http://topepo.github.io/caret/measuring-performance.html#lift-curves)). Nous travaillons toujours sur l‚Äô√©chantillon test. Pour la construire, en sus des classes observ√©es, nous avons besoin de la probabilit√© (score) d‚Äô√™tre de la classe positive fournie par le mod√®le [P(is_genuine = True / description)].

```{r}
#score des individus positifs (vrai billets) 
score = predict(m_lr, test, type="prob")[,"True"]
```
Avec l‚Äôoption ‚Äútype = prob‚Äù, predict() produit pour chaque individu les probabilit√©s d‚Äôappartenance aux classes.

Nous cr√©ons un data frame regroupant les classes observ√©es et les scores.
```{r}
# tableau de donn√©es pour le scoring 
liftdata <- data.frame(classe=test$is_genuine) 
liftdata$score <- score
```

Nous faisons appel √† la fonction lift() de caret en sp√©cifiant la modalit√© cible pour le scoring, √† savoir ‚Äúclass = True‚Äù.

```{r}
#objet lift 
lift_obj = lift(classe ~ score, data=liftdata, class="True") 
print(lift_obj)
```
- La fonction print() indique seulement la proportion des observations positives (is_genuine = True).

Pour obtenir la courbe proprement dite, nous appelons la fonction plot() associ√©e √† l‚Äôobjet.
```{r}
#affichage de la courbe lift 
plot(lift_obj)
```

- La courbe est proche de la limite th√©orique (atteinte lorsque tous les billets = True se voient attribuer un score plus √©lev√© que les billets = False). Notre ciblage est d‚Äôexcellente qualit√©.

#### La Courbe ROC
La courbe ROC vise √† mesurer la qualit√© d‚Äôun mod√®le en s‚Äôaffranchissant des co√ªts de mauvaise affectation et de la repr√©sentativit√© de l‚Äô√©chantillon utilis√© (les proportions des classes dans l‚Äô√©chantillon peut √™tre diff√©rent de celui de la population).

```{r, warning=FALSE}
#library 
library(pROC)

#objet roc 
roc_obj = roc(test$is_genuine =="True",score)

#plot de l'objet roc 
plot(1-roc_obj$specificities, roc_obj$sensitivities, type="l", col = "red", xlab ="False positive rate", ylab = "True positive rate" ) 
abline(0,1)
```

- Pour maximiser le recall (TP rate: axe des y) (le ratio de faux billets), on choisis un cutoff de 0.8 (p(T) > 0.8).

## Tester le mod√®le final sur un nouveau jeu de donn√©es
```{r}
# importer le jeu de donn√©es
new_df = read.csv("data/billets_production.csv", sep = ',')
#new_df = read.csv("data/test2.csv", sep = ';')
#new_df = read.csv("data/billets_essai.csv", sep = ',')

# prediction 
pred_new = predict(m_lr, newdata=new_df) 

#distribution des classes pr√©dites 
print(table(pred_new))

#score des individus positifs (vrai billets) 
score2 = predict(m_lr, new_df, type="prob")[,"True"]

# tableau de donn√©es pour le scoring 
liftdata_new <- data.frame(classe=new_df$id) 
liftdata_new$score <- score2

# Ajouter les pr√©dictions au fichier original
df4 = new_df %>% mutate(prediction = pred_new, Proba_vrai = score2)
kable(df4, caption = "Mes r√©sultats")
```

* Les billets A_1, A_2 et A_3 sont des faux billets (score faible) et es 2 autres sont des vrai billets avec une forte probabilit√©


# Impl√©menter le mod√®le de r√©gression logistique avec shiny
Construire un outil qui prend comme entr√©e un fichier CSV des donn√©es que vous voulez obtenir des pr√©dictions et la sortie sera les valeurs pr√©dites ([tuto](https://www.r-bloggers.com/2021/01/how-to-share-your-machine-learning-models-with-shiny/)).

```{r}
# Enregistrer notre mod√®le final
saveRDS(m_lr, "regressionModel.rds")
```

# R√©f√©rences
[Atelier sur les mod√®les lin√©aires](http://r.qcbs.ca/workshop06/pres-fr/workshop06-pres-fr.html#121)

[R√©gression lin√©aire multiple, sthda](http://www.sthda.com/english/articles/40-regression-analysis/168-multiple-linear-regression-in-r/)

[Multicolin√©arit√© des variables, sthda](http://www.sthda.com/english/articles/39-regression-model-diagnostics/160-multicollinearity-essentials-and-vif-in-r/)

[Max Kuhn, ‚ÄúThe caret Package‚Äù](http://topepo.github.io/caret/index.html)

# Session info
```{r}
sessionInfo()
```
